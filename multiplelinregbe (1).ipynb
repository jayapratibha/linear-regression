{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport sklearn ","metadata":{"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"pip install statsmodels","metadata":{"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"Requirement already satisfied: statsmodels in /srv/conda/envs/notebook/lib/python3.7/site-packages (0.11.1)\nRequirement already satisfied: patsy>=0.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from statsmodels) (0.5.1)\nRequirement already satisfied: pandas>=0.21 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from statsmodels) (0.24.2)\nRequirement already satisfied: numpy>=1.14 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from statsmodels) (1.18.5)\nRequirement already satisfied: scipy>=1.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from statsmodels) (1.5.0)\nRequirement already satisfied: six in /srv/conda/envs/notebook/lib/python3.7/site-packages (from patsy>=0.5->statsmodels) (1.15.0)\nRequirement already satisfied: python-dateutil>=2.5.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas>=0.21->statsmodels) (2.8.1)\nRequirement already satisfied: pytz>=2011k in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas>=0.21->statsmodels) (2020.1)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import statsmodels.formula.api as sm","metadata":{"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"#importing the dataset\ndataset = pd.read_csv('50_Startups.csv')\nX = dataset.iloc[:,:-1].values \ny = dataset.iloc[:,4].values","metadata":{"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"# encoding categorical data\n# encoding the independent varaible ie the label\n\nfrom sklearn.preprocessing import LabelEncoder , OneHotEncoder\nlabelencoder_X = LabelEncoder()\n(X[:,3])=labelencoder_X.fit_transform(X[:,3])","metadata":{"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\n\nct = ColumnTransformer(\n    [('one_hot_encoder', OneHotEncoder(categories='auto'), [3])],   # The column numbers to be transformed (here is [0] but can be [0, 1, 3])\n    remainder='passthrough'                                         # Leave the rest of the columns untouched\n)\n\nX = ct.fit_transform(X)","metadata":{"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"trusted":true},"execution_count":78,"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"array([[0.0, 0.0, 1.0, 165349.2, 136897.8, 471784.1],\n       [1.0, 0.0, 0.0, 162597.7, 151377.59, 443898.53],\n       [0.0, 1.0, 0.0, 153441.51, 101145.55, 407934.54],\n       [0.0, 0.0, 1.0, 144372.41, 118671.85, 383199.62],\n       [0.0, 1.0, 0.0, 142107.34, 91391.77, 366168.42],\n       [0.0, 0.0, 1.0, 131876.9, 99814.71, 362861.36],\n       [1.0, 0.0, 0.0, 134615.46, 147198.87, 127716.82],\n       [0.0, 1.0, 0.0, 130298.13, 145530.06, 323876.68],\n       [0.0, 0.0, 1.0, 120542.52, 148718.95, 311613.29],\n       [1.0, 0.0, 0.0, 123334.88, 108679.17, 304981.62],\n       [0.0, 1.0, 0.0, 101913.08, 110594.11, 229160.95],\n       [1.0, 0.0, 0.0, 100671.96, 91790.61, 249744.55],\n       [0.0, 1.0, 0.0, 93863.75, 127320.38, 249839.44],\n       [1.0, 0.0, 0.0, 91992.39, 135495.07, 252664.93],\n       [0.0, 1.0, 0.0, 119943.24, 156547.42, 256512.92],\n       [0.0, 0.0, 1.0, 114523.61, 122616.84, 261776.23],\n       [1.0, 0.0, 0.0, 78013.11, 121597.55, 264346.06],\n       [0.0, 0.0, 1.0, 94657.16, 145077.58, 282574.31],\n       [0.0, 1.0, 0.0, 91749.16, 114175.79, 294919.57],\n       [0.0, 0.0, 1.0, 86419.7, 153514.11, 0.0],\n       [1.0, 0.0, 0.0, 76253.86, 113867.3, 298664.47],\n       [0.0, 0.0, 1.0, 78389.47, 153773.43, 299737.29],\n       [0.0, 1.0, 0.0, 73994.56, 122782.75, 303319.26],\n       [0.0, 1.0, 0.0, 67532.53, 105751.03, 304768.73],\n       [0.0, 0.0, 1.0, 77044.01, 99281.34, 140574.81],\n       [1.0, 0.0, 0.0, 64664.71, 139553.16, 137962.62],\n       [0.0, 1.0, 0.0, 75328.87, 144135.98, 134050.07],\n       [0.0, 0.0, 1.0, 72107.6, 127864.55, 353183.81],\n       [0.0, 1.0, 0.0, 66051.52, 182645.56, 118148.2],\n       [0.0, 0.0, 1.0, 65605.48, 153032.06, 107138.38],\n       [0.0, 1.0, 0.0, 61994.48, 115641.28, 91131.24],\n       [0.0, 0.0, 1.0, 61136.38, 152701.92, 88218.23],\n       [1.0, 0.0, 0.0, 63408.86, 129219.61, 46085.25],\n       [0.0, 1.0, 0.0, 55493.95, 103057.49, 214634.81],\n       [1.0, 0.0, 0.0, 46426.07, 157693.92, 210797.67],\n       [0.0, 0.0, 1.0, 46014.02, 85047.44, 205517.64],\n       [0.0, 1.0, 0.0, 28663.76, 127056.21, 201126.82],\n       [1.0, 0.0, 0.0, 44069.95, 51283.14, 197029.42],\n       [0.0, 0.0, 1.0, 20229.59, 65947.93, 185265.1],\n       [1.0, 0.0, 0.0, 38558.51, 82982.09, 174999.3],\n       [1.0, 0.0, 0.0, 28754.33, 118546.05, 172795.67],\n       [0.0, 1.0, 0.0, 27892.92, 84710.77, 164470.71],\n       [1.0, 0.0, 0.0, 23640.93, 96189.63, 148001.11],\n       [0.0, 0.0, 1.0, 15505.73, 127382.3, 35534.17],\n       [1.0, 0.0, 0.0, 22177.74, 154806.14, 28334.72],\n       [0.0, 0.0, 1.0, 1000.23, 124153.04, 1903.93],\n       [0.0, 1.0, 0.0, 1315.46, 115816.21, 297114.46],\n       [1.0, 0.0, 0.0, 0.0, 135426.92, 0.0],\n       [0.0, 0.0, 1.0, 542.05, 51743.15, 0.0],\n       [1.0, 0.0, 0.0, 0.0, 116983.8, 45173.06]], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2 , random_state = 0)","metadata":{"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"trusted":true},"execution_count":80,"outputs":[{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"array([[0.0, 1.0, 0.0, 55493.95, 103057.49, 214634.81],\n       [0.0, 0.0, 1.0, 46014.02, 85047.44, 205517.64],\n       [0.0, 1.0, 0.0, 75328.87, 144135.98, 134050.07],\n       [1.0, 0.0, 0.0, 46426.07, 157693.92, 210797.67],\n       [0.0, 1.0, 0.0, 91749.16, 114175.79, 294919.57],\n       [0.0, 1.0, 0.0, 130298.13, 145530.06, 323876.68],\n       [0.0, 1.0, 0.0, 119943.24, 156547.42, 256512.92],\n       [0.0, 0.0, 1.0, 1000.23, 124153.04, 1903.93],\n       [0.0, 0.0, 1.0, 542.05, 51743.15, 0.0],\n       [0.0, 0.0, 1.0, 65605.48, 153032.06, 107138.38],\n       [0.0, 0.0, 1.0, 114523.61, 122616.84, 261776.23],\n       [0.0, 1.0, 0.0, 61994.48, 115641.28, 91131.24],\n       [1.0, 0.0, 0.0, 63408.86, 129219.61, 46085.25],\n       [1.0, 0.0, 0.0, 78013.11, 121597.55, 264346.06],\n       [1.0, 0.0, 0.0, 23640.93, 96189.63, 148001.11],\n       [1.0, 0.0, 0.0, 76253.86, 113867.3, 298664.47],\n       [0.0, 0.0, 1.0, 15505.73, 127382.3, 35534.17],\n       [0.0, 0.0, 1.0, 120542.52, 148718.95, 311613.29],\n       [1.0, 0.0, 0.0, 91992.39, 135495.07, 252664.93],\n       [1.0, 0.0, 0.0, 64664.71, 139553.16, 137962.62],\n       [0.0, 0.0, 1.0, 131876.9, 99814.71, 362861.36],\n       [0.0, 0.0, 1.0, 94657.16, 145077.58, 282574.31],\n       [1.0, 0.0, 0.0, 28754.33, 118546.05, 172795.67],\n       [1.0, 0.0, 0.0, 0.0, 116983.8, 45173.06],\n       [1.0, 0.0, 0.0, 162597.7, 151377.59, 443898.53],\n       [0.0, 1.0, 0.0, 93863.75, 127320.38, 249839.44],\n       [1.0, 0.0, 0.0, 44069.95, 51283.14, 197029.42],\n       [0.0, 0.0, 1.0, 77044.01, 99281.34, 140574.81],\n       [1.0, 0.0, 0.0, 134615.46, 147198.87, 127716.82],\n       [0.0, 1.0, 0.0, 67532.53, 105751.03, 304768.73],\n       [0.0, 1.0, 0.0, 28663.76, 127056.21, 201126.82],\n       [0.0, 0.0, 1.0, 78389.47, 153773.43, 299737.29],\n       [0.0, 0.0, 1.0, 86419.7, 153514.11, 0.0],\n       [1.0, 0.0, 0.0, 123334.88, 108679.17, 304981.62],\n       [1.0, 0.0, 0.0, 38558.51, 82982.09, 174999.3],\n       [0.0, 1.0, 0.0, 1315.46, 115816.21, 297114.46],\n       [0.0, 0.0, 1.0, 144372.41, 118671.85, 383199.62],\n       [0.0, 0.0, 1.0, 165349.2, 136897.8, 471784.1],\n       [1.0, 0.0, 0.0, 0.0, 135426.92, 0.0],\n       [1.0, 0.0, 0.0, 22177.74, 154806.14, 28334.72]], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"X_test","metadata":{"trusted":true},"execution_count":81,"outputs":[{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"array([[0.0, 1.0, 0.0, 66051.52, 182645.56, 118148.2],\n       [1.0, 0.0, 0.0, 100671.96, 91790.61, 249744.55],\n       [0.0, 1.0, 0.0, 101913.08, 110594.11, 229160.95],\n       [0.0, 1.0, 0.0, 27892.92, 84710.77, 164470.71],\n       [0.0, 1.0, 0.0, 153441.51, 101145.55, 407934.54],\n       [0.0, 0.0, 1.0, 72107.6, 127864.55, 353183.81],\n       [0.0, 0.0, 1.0, 20229.59, 65947.93, 185265.1],\n       [0.0, 0.0, 1.0, 61136.38, 152701.92, 88218.23],\n       [0.0, 1.0, 0.0, 73994.56, 122782.75, 303319.26],\n       [0.0, 1.0, 0.0, 142107.34, 91391.77, 366168.42]], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"y_train","metadata":{"trusted":true},"execution_count":82,"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"array([ 96778.92,  96479.51, 105733.54,  96712.8 , 124266.9 , 155752.6 ,\n       132602.65,  64926.08,  35673.41, 101004.64, 129917.04,  99937.59,\n        97427.84, 126992.93,  71498.49, 118474.03,  69758.98, 152211.77,\n       134307.35, 107404.34, 156991.12, 125370.37,  78239.91,  14681.4 ,\n       191792.06, 141585.52,  89949.14, 108552.04, 156122.51, 108733.99,\n        90708.19, 111313.02, 122776.86, 149759.96,  81005.76,  49490.75,\n       182901.99, 192261.83,  42559.73,  65200.33])"},"metadata":{}}]},{"cell_type":"code","source":"y_test","metadata":{"trusted":true},"execution_count":83,"outputs":[{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"array([103282.38, 144259.4 , 146121.95,  77798.83, 191050.39, 105008.31,\n        81229.06,  97483.56, 110352.25, 166187.94])"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nimport statsmodels.regression.linear_model as sm\nregressor = LinearRegression()\nregressor.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":84,"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"},"metadata":{}}]},{"cell_type":"code","source":"\n# predicting the tests set results\ny_pred = regressor.predict(X_test)","metadata":{"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"y_pred","metadata":{"trusted":true},"execution_count":86,"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"array([103015.20159795, 132582.27760816, 132447.73845175,  71976.09851258,\n       178537.48221057, 116161.24230167,  67851.69209676,  98791.73374687,\n       113969.43533014, 167921.06569552])"},"metadata":{}}]},{"cell_type":"code","source":"y_test","metadata":{"trusted":true},"execution_count":87,"outputs":[{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"array([103282.38, 144259.4 , 146121.95,  77798.83, 191050.39, 105008.31,\n        81229.06,  97483.56, 110352.25, 166187.94])"},"metadata":{}}]},{"cell_type":"code","source":"# compare real and predicted profit","metadata":{"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"X = np.append(np.ones((50,1)).astype(int) ,values=X , axis=1)","metadata":{"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"# below we create a matrix containing only high impact independent varaibles so remove one by one","metadata":{"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"X_opt = X[:,[0,1,2,3,4,5]]","metadata":{"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"X_opt","metadata":{"trusted":true},"execution_count":92,"outputs":[{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"array([[1, 0.0, 0.0, 1.0, 165349.2, 136897.8],\n       [1, 1.0, 0.0, 0.0, 162597.7, 151377.59],\n       [1, 0.0, 1.0, 0.0, 153441.51, 101145.55],\n       [1, 0.0, 0.0, 1.0, 144372.41, 118671.85],\n       [1, 0.0, 1.0, 0.0, 142107.34, 91391.77],\n       [1, 0.0, 0.0, 1.0, 131876.9, 99814.71],\n       [1, 1.0, 0.0, 0.0, 134615.46, 147198.87],\n       [1, 0.0, 1.0, 0.0, 130298.13, 145530.06],\n       [1, 0.0, 0.0, 1.0, 120542.52, 148718.95],\n       [1, 1.0, 0.0, 0.0, 123334.88, 108679.17],\n       [1, 0.0, 1.0, 0.0, 101913.08, 110594.11],\n       [1, 1.0, 0.0, 0.0, 100671.96, 91790.61],\n       [1, 0.0, 1.0, 0.0, 93863.75, 127320.38],\n       [1, 1.0, 0.0, 0.0, 91992.39, 135495.07],\n       [1, 0.0, 1.0, 0.0, 119943.24, 156547.42],\n       [1, 0.0, 0.0, 1.0, 114523.61, 122616.84],\n       [1, 1.0, 0.0, 0.0, 78013.11, 121597.55],\n       [1, 0.0, 0.0, 1.0, 94657.16, 145077.58],\n       [1, 0.0, 1.0, 0.0, 91749.16, 114175.79],\n       [1, 0.0, 0.0, 1.0, 86419.7, 153514.11],\n       [1, 1.0, 0.0, 0.0, 76253.86, 113867.3],\n       [1, 0.0, 0.0, 1.0, 78389.47, 153773.43],\n       [1, 0.0, 1.0, 0.0, 73994.56, 122782.75],\n       [1, 0.0, 1.0, 0.0, 67532.53, 105751.03],\n       [1, 0.0, 0.0, 1.0, 77044.01, 99281.34],\n       [1, 1.0, 0.0, 0.0, 64664.71, 139553.16],\n       [1, 0.0, 1.0, 0.0, 75328.87, 144135.98],\n       [1, 0.0, 0.0, 1.0, 72107.6, 127864.55],\n       [1, 0.0, 1.0, 0.0, 66051.52, 182645.56],\n       [1, 0.0, 0.0, 1.0, 65605.48, 153032.06],\n       [1, 0.0, 1.0, 0.0, 61994.48, 115641.28],\n       [1, 0.0, 0.0, 1.0, 61136.38, 152701.92],\n       [1, 1.0, 0.0, 0.0, 63408.86, 129219.61],\n       [1, 0.0, 1.0, 0.0, 55493.95, 103057.49],\n       [1, 1.0, 0.0, 0.0, 46426.07, 157693.92],\n       [1, 0.0, 0.0, 1.0, 46014.02, 85047.44],\n       [1, 0.0, 1.0, 0.0, 28663.76, 127056.21],\n       [1, 1.0, 0.0, 0.0, 44069.95, 51283.14],\n       [1, 0.0, 0.0, 1.0, 20229.59, 65947.93],\n       [1, 1.0, 0.0, 0.0, 38558.51, 82982.09],\n       [1, 1.0, 0.0, 0.0, 28754.33, 118546.05],\n       [1, 0.0, 1.0, 0.0, 27892.92, 84710.77],\n       [1, 1.0, 0.0, 0.0, 23640.93, 96189.63],\n       [1, 0.0, 0.0, 1.0, 15505.73, 127382.3],\n       [1, 1.0, 0.0, 0.0, 22177.74, 154806.14],\n       [1, 0.0, 0.0, 1.0, 1000.23, 124153.04],\n       [1, 0.0, 1.0, 0.0, 1315.46, 115816.21],\n       [1, 1.0, 0.0, 0.0, 0.0, 135426.92],\n       [1, 0.0, 0.0, 1.0, 542.05, 51743.15],\n       [1, 1.0, 0.0, 0.0, 0.0, 116983.8]], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"X_opt = np.array(X_opt, dtype=float)","metadata":{"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"X_opt","metadata":{"trusted":true},"execution_count":94,"outputs":[{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"array([[1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n        1.6534920e+05, 1.3689780e+05],\n       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        1.6259770e+05, 1.5137759e+05],\n       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n        1.5344151e+05, 1.0114555e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n        1.4437241e+05, 1.1867185e+05],\n       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n        1.4210734e+05, 9.1391770e+04],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n        1.3187690e+05, 9.9814710e+04],\n       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        1.3461546e+05, 1.4719887e+05],\n       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n        1.3029813e+05, 1.4553006e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n        1.2054252e+05, 1.4871895e+05],\n       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        1.2333488e+05, 1.0867917e+05],\n       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n        1.0191308e+05, 1.1059411e+05],\n       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        1.0067196e+05, 9.1790610e+04],\n       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n        9.3863750e+04, 1.2732038e+05],\n       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        9.1992390e+04, 1.3549507e+05],\n       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n        1.1994324e+05, 1.5654742e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n        1.1452361e+05, 1.2261684e+05],\n       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        7.8013110e+04, 1.2159755e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n        9.4657160e+04, 1.4507758e+05],\n       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n        9.1749160e+04, 1.1417579e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n        8.6419700e+04, 1.5351411e+05],\n       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        7.6253860e+04, 1.1386730e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n        7.8389470e+04, 1.5377343e+05],\n       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n        7.3994560e+04, 1.2278275e+05],\n       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n        6.7532530e+04, 1.0575103e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n        7.7044010e+04, 9.9281340e+04],\n       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        6.4664710e+04, 1.3955316e+05],\n       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n        7.5328870e+04, 1.4413598e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n        7.2107600e+04, 1.2786455e+05],\n       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n        6.6051520e+04, 1.8264556e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n        6.5605480e+04, 1.5303206e+05],\n       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n        6.1994480e+04, 1.1564128e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n        6.1136380e+04, 1.5270192e+05],\n       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        6.3408860e+04, 1.2921961e+05],\n       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n        5.5493950e+04, 1.0305749e+05],\n       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        4.6426070e+04, 1.5769392e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n        4.6014020e+04, 8.5047440e+04],\n       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n        2.8663760e+04, 1.2705621e+05],\n       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        4.4069950e+04, 5.1283140e+04],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n        2.0229590e+04, 6.5947930e+04],\n       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        3.8558510e+04, 8.2982090e+04],\n       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        2.8754330e+04, 1.1854605e+05],\n       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n        2.7892920e+04, 8.4710770e+04],\n       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        2.3640930e+04, 9.6189630e+04],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n        1.5505730e+04, 1.2738230e+05],\n       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        2.2177740e+04, 1.5480614e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n        1.0002300e+03, 1.2415304e+05],\n       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n        1.3154600e+03, 1.1581621e+05],\n       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        0.0000000e+00, 1.3542692e+05],\n       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n        5.4205000e+02, 5.1743150e+04],\n       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n        0.0000000e+00, 1.1698380e+05]])"},"metadata":{}}]},{"cell_type":"code","source":"\nregressor_ols = sm.OLS(endog = y,exog = X_opt).fit()","metadata":{"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"import statsmodels.api as sm","metadata":{"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"# above we have fit the model with all possile predictors","metadata":{"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"regressor_ols.summary()","metadata":{"trusted":true},"execution_count":98,"outputs":[{"execution_count":98,"output_type":"execute_result","data":{"text/plain":"<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.948\nModel:                            OLS   Adj. R-squared:                  0.943\nMethod:                 Least Squares   F-statistic:                     205.0\nDate:                Mon, 17 Aug 2020   Prob (F-statistic):           2.90e-28\nTime:                        06:30:18   Log-Likelihood:                -526.75\nNo. Observations:                  50   AIC:                             1064.\nDf Residuals:                      45   BIC:                             1073.\nDf Model:                           4                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst       4.122e+04   4607.941      8.945      0.000    3.19e+04    5.05e+04\nx1          1.339e+04   2421.500      5.529      0.000    8511.111    1.83e+04\nx2          1.448e+04   2518.987      5.748      0.000    9405.870    1.96e+04\nx3          1.335e+04   2459.306      5.428      0.000    8395.623    1.83e+04\nx4             0.8609      0.031     27.665      0.000       0.798       0.924\nx5            -0.0527      0.050     -1.045      0.301      -0.154       0.049\n==============================================================================\nOmnibus:                       14.275   Durbin-Watson:                   1.197\nProb(Omnibus):                  0.001   Jarque-Bera (JB):               19.260\nSkew:                          -0.953   Prob(JB):                     6.57e-05\nKurtosis:                       5.369   Cond. No.                     3.34e+17\n==============================================================================\n\nWarnings:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The smallest eigenvalue is 9.69e-24. This might indicate that there are\nstrong multicollinearity problems or that the design matrix is singular.\n\"\"\"","text/html":"<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.948</td>\n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.943</td>\n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   205.0</td>\n</tr>\n<tr>\n  <th>Date:</th>             <td>Mon, 17 Aug 2020</td> <th>  Prob (F-statistic):</th> <td>2.90e-28</td>\n</tr>\n<tr>\n  <th>Time:</th>                 <td>06:30:18</td>     <th>  Log-Likelihood:    </th> <td> -526.75</td>\n</tr>\n<tr>\n  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1064.</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td>    45</td>      <th>  BIC:               </th> <td>   1073.</td>\n</tr>\n<tr>\n  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>const</th> <td> 4.122e+04</td> <td> 4607.941</td> <td>    8.945</td> <td> 0.000</td> <td> 3.19e+04</td> <td> 5.05e+04</td>\n</tr>\n<tr>\n  <th>x1</th>    <td> 1.339e+04</td> <td> 2421.500</td> <td>    5.529</td> <td> 0.000</td> <td> 8511.111</td> <td> 1.83e+04</td>\n</tr>\n<tr>\n  <th>x2</th>    <td> 1.448e+04</td> <td> 2518.987</td> <td>    5.748</td> <td> 0.000</td> <td> 9405.870</td> <td> 1.96e+04</td>\n</tr>\n<tr>\n  <th>x3</th>    <td> 1.335e+04</td> <td> 2459.306</td> <td>    5.428</td> <td> 0.000</td> <td> 8395.623</td> <td> 1.83e+04</td>\n</tr>\n<tr>\n  <th>x4</th>    <td>    0.8609</td> <td>    0.031</td> <td>   27.665</td> <td> 0.000</td> <td>    0.798</td> <td>    0.924</td>\n</tr>\n<tr>\n  <th>x5</th>    <td>   -0.0527</td> <td>    0.050</td> <td>   -1.045</td> <td> 0.301</td> <td>   -0.154</td> <td>    0.049</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td>14.275</td> <th>  Durbin-Watson:     </th> <td>   1.197</td>\n</tr>\n<tr>\n  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  19.260</td>\n</tr>\n<tr>\n  <th>Skew:</th>          <td>-0.953</td> <th>  Prob(JB):          </th> <td>6.57e-05</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>      <td> 5.369</td> <th>  Cond. No.          </th> <td>3.34e+17</td>\n</tr>\n</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 9.69e-24. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."},"metadata":{}}]},{"cell_type":"code","source":"# above see p values the lower the p valuse the more significance it will be select highest and remove it varaibles","metadata":{"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"X_opt = X[:,[0,1,2,3,4]]\nX_opt = np.array(X_opt, dtype=float)\nregressor_ols = sm.OLS(endog = y,exog = X_opt).fit()\nregressor_ols.summary()","metadata":{"trusted":true},"execution_count":100,"outputs":[{"execution_count":100,"output_type":"execute_result","data":{"text/plain":"<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.947\nModel:                            OLS   Adj. R-squared:                  0.943\nMethod:                 Least Squares   F-statistic:                     272.4\nDate:                Mon, 17 Aug 2020   Prob (F-statistic):           2.76e-29\nTime:                        06:31:54   Log-Likelihood:                -527.35\nNo. Observations:                  50   AIC:                             1063.\nDf Residuals:                      46   BIC:                             1070.\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst       3.686e+04   1959.786     18.806      0.000    3.29e+04    4.08e+04\nx1          1.189e+04   1956.677      6.079      0.000    7955.697    1.58e+04\nx2          1.306e+04   2122.665      6.152      0.000    8785.448    1.73e+04\nx3           1.19e+04   2036.022      5.847      0.000    7805.580     1.6e+04\nx4             0.8530      0.030     28.226      0.000       0.792       0.914\n==============================================================================\nOmnibus:                       13.418   Durbin-Watson:                   1.122\nProb(Omnibus):                  0.001   Jarque-Bera (JB):               17.605\nSkew:                          -0.907   Prob(JB):                     0.000150\nKurtosis:                       5.271   Cond. No.                     3.20e+17\n==============================================================================\n\nWarnings:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The smallest eigenvalue is 3.66e-24. This might indicate that there are\nstrong multicollinearity problems or that the design matrix is singular.\n\"\"\"","text/html":"<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.947</td>\n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.943</td>\n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   272.4</td>\n</tr>\n<tr>\n  <th>Date:</th>             <td>Mon, 17 Aug 2020</td> <th>  Prob (F-statistic):</th> <td>2.76e-29</td>\n</tr>\n<tr>\n  <th>Time:</th>                 <td>06:31:54</td>     <th>  Log-Likelihood:    </th> <td> -527.35</td>\n</tr>\n<tr>\n  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1063.</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td>    46</td>      <th>  BIC:               </th> <td>   1070.</td>\n</tr>\n<tr>\n  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>const</th> <td> 3.686e+04</td> <td> 1959.786</td> <td>   18.806</td> <td> 0.000</td> <td> 3.29e+04</td> <td> 4.08e+04</td>\n</tr>\n<tr>\n  <th>x1</th>    <td> 1.189e+04</td> <td> 1956.677</td> <td>    6.079</td> <td> 0.000</td> <td> 7955.697</td> <td> 1.58e+04</td>\n</tr>\n<tr>\n  <th>x2</th>    <td> 1.306e+04</td> <td> 2122.665</td> <td>    6.152</td> <td> 0.000</td> <td> 8785.448</td> <td> 1.73e+04</td>\n</tr>\n<tr>\n  <th>x3</th>    <td>  1.19e+04</td> <td> 2036.022</td> <td>    5.847</td> <td> 0.000</td> <td> 7805.580</td> <td>  1.6e+04</td>\n</tr>\n<tr>\n  <th>x4</th>    <td>    0.8530</td> <td>    0.030</td> <td>   28.226</td> <td> 0.000</td> <td>    0.792</td> <td>    0.914</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td>13.418</td> <th>  Durbin-Watson:     </th> <td>   1.122</td>\n</tr>\n<tr>\n  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  17.605</td>\n</tr>\n<tr>\n  <th>Skew:</th>          <td>-0.907</td> <th>  Prob(JB):          </th> <td>0.000150</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>      <td> 5.271</td> <th>  Cond. No.          </th> <td>3.20e+17</td>\n</tr>\n</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 3.66e-24. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."},"metadata":{}}]},{"cell_type":"code","source":"X_opt = X[:,[0,1,2,3]]\nX_opt = np.array(X_opt, dtype=float)\nregressor_ols = sm.OLS(endog = y,exog = X_opt).fit()\nregressor_ols.summary()","metadata":{"trusted":true},"execution_count":101,"outputs":[{"execution_count":101,"output_type":"execute_result","data":{"text/plain":"<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.024\nModel:                            OLS   Adj. R-squared:                 -0.018\nMethod:                 Least Squares   F-statistic:                    0.5748\nDate:                Mon, 17 Aug 2020   Prob (F-statistic):              0.567\nTime:                        06:32:18   Log-Likelihood:                -600.05\nNo. Observations:                  50   AIC:                             1206.\nDf Residuals:                      47   BIC:                             1212.\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst       8.411e+04   4314.466     19.495      0.000    7.54e+04    9.28e+04\nx1           1.98e+04   8200.033      2.414      0.020    3299.925    3.63e+04\nx2          3.467e+04   8383.297      4.135      0.000    1.78e+04    5.15e+04\nx3          2.965e+04   8200.033      3.616      0.001    1.32e+04    4.61e+04\n==============================================================================\nOmnibus:                        0.111   Durbin-Watson:                   0.081\nProb(Omnibus):                  0.946   Jarque-Bera (JB):                0.207\nSkew:                           0.104   Prob(JB):                        0.902\nKurtosis:                       2.762   Cond. No.                     6.52e+16\n==============================================================================\n\nWarnings:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The smallest eigenvalue is 1.57e-32. This might indicate that there are\nstrong multicollinearity problems or that the design matrix is singular.\n\"\"\"","text/html":"<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.024</td>\n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.018</td>\n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>  0.5748</td>\n</tr>\n<tr>\n  <th>Date:</th>             <td>Mon, 17 Aug 2020</td> <th>  Prob (F-statistic):</th>  <td> 0.567</td> \n</tr>\n<tr>\n  <th>Time:</th>                 <td>06:32:18</td>     <th>  Log-Likelihood:    </th> <td> -600.05</td>\n</tr>\n<tr>\n  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1206.</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td>    47</td>      <th>  BIC:               </th> <td>   1212.</td>\n</tr>\n<tr>\n  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>const</th> <td> 8.411e+04</td> <td> 4314.466</td> <td>   19.495</td> <td> 0.000</td> <td> 7.54e+04</td> <td> 9.28e+04</td>\n</tr>\n<tr>\n  <th>x1</th>    <td>  1.98e+04</td> <td> 8200.033</td> <td>    2.414</td> <td> 0.020</td> <td> 3299.925</td> <td> 3.63e+04</td>\n</tr>\n<tr>\n  <th>x2</th>    <td> 3.467e+04</td> <td> 8383.297</td> <td>    4.135</td> <td> 0.000</td> <td> 1.78e+04</td> <td> 5.15e+04</td>\n</tr>\n<tr>\n  <th>x3</th>    <td> 2.965e+04</td> <td> 8200.033</td> <td>    3.616</td> <td> 0.001</td> <td> 1.32e+04</td> <td> 4.61e+04</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td> 0.111</td> <th>  Durbin-Watson:     </th> <td>   0.081</td>\n</tr>\n<tr>\n  <th>Prob(Omnibus):</th> <td> 0.946</td> <th>  Jarque-Bera (JB):  </th> <td>   0.207</td>\n</tr>\n<tr>\n  <th>Skew:</th>          <td> 0.104</td> <th>  Prob(JB):          </th> <td>   0.902</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>      <td> 2.762</td> <th>  Cond. No.          </th> <td>6.52e+16</td>\n</tr>\n</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 1.57e-32. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."},"metadata":{}}]},{"cell_type":"code","source":"X_opt = X[:,[0,1,2]]\nX_opt = np.array(X_opt, dtype=float)\nregressor_ols = sm.OLS(endog = y,exog = X_opt).fit()\nregressor_ols.summary()","metadata":{"trusted":true},"execution_count":103,"outputs":[{"execution_count":103,"output_type":"execute_result","data":{"text/plain":"<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.024\nModel:                            OLS   Adj. R-squared:                 -0.018\nMethod:                 Least Squares   F-statistic:                    0.5748\nDate:                Mon, 17 Aug 2020   Prob (F-statistic):              0.567\nTime:                        06:33:37   Log-Likelihood:                -600.05\nNo. Observations:                  50   AIC:                             1206.\nDf Residuals:                      47   BIC:                             1212.\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst       1.138e+05   9861.636     11.535      0.000    9.39e+04    1.34e+05\nx1         -9851.2712   1.39e+04     -0.706      0.483   -3.79e+04    1.82e+04\nx2          5017.5779   1.42e+04      0.354      0.725   -2.35e+04    3.35e+04\n==============================================================================\nOmnibus:                        0.111   Durbin-Watson:                   0.081\nProb(Omnibus):                  0.946   Jarque-Bera (JB):                0.207\nSkew:                           0.104   Prob(JB):                        0.902\nKurtosis:                       2.762   Cond. No.                         3.70\n==============================================================================\n\nWarnings:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\"\"\"","text/html":"<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.024</td>\n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.018</td>\n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>  0.5748</td>\n</tr>\n<tr>\n  <th>Date:</th>             <td>Mon, 17 Aug 2020</td> <th>  Prob (F-statistic):</th>  <td> 0.567</td> \n</tr>\n<tr>\n  <th>Time:</th>                 <td>06:33:37</td>     <th>  Log-Likelihood:    </th> <td> -600.05</td>\n</tr>\n<tr>\n  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1206.</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td>    47</td>      <th>  BIC:               </th> <td>   1212.</td>\n</tr>\n<tr>\n  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>const</th> <td> 1.138e+05</td> <td> 9861.636</td> <td>   11.535</td> <td> 0.000</td> <td> 9.39e+04</td> <td> 1.34e+05</td>\n</tr>\n<tr>\n  <th>x1</th>    <td>-9851.2712</td> <td> 1.39e+04</td> <td>   -0.706</td> <td> 0.483</td> <td>-3.79e+04</td> <td> 1.82e+04</td>\n</tr>\n<tr>\n  <th>x2</th>    <td> 5017.5779</td> <td> 1.42e+04</td> <td>    0.354</td> <td> 0.725</td> <td>-2.35e+04</td> <td> 3.35e+04</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td> 0.111</td> <th>  Durbin-Watson:     </th> <td>   0.081</td>\n</tr>\n<tr>\n  <th>Prob(Omnibus):</th> <td> 0.946</td> <th>  Jarque-Bera (JB):  </th> <td>   0.207</td>\n</tr>\n<tr>\n  <th>Skew:</th>          <td> 0.104</td> <th>  Prob(JB):          </th> <td>   0.902</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>      <td> 2.762</td> <th>  Cond. No.          </th> <td>    3.70</td>\n</tr>\n</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."},"metadata":{}}]},{"cell_type":"code","source":"X_opt = X[:,[0,1]]\nX_opt = np.array(X_opt, dtype=float)\nregressor_ols = sm.OLS(endog = y,exog = X_opt).fit()\nregressor_ols.summary()","metadata":{"trusted":true},"execution_count":104,"outputs":[{"execution_count":104,"output_type":"execute_result","data":{"text/plain":"<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.021\nModel:                            OLS   Adj. R-squared:                  0.001\nMethod:                 Least Squares   F-statistic:                     1.043\nDate:                Mon, 17 Aug 2020   Prob (F-statistic):              0.312\nTime:                        06:33:46   Log-Likelihood:                -600.12\nNo. Observations:                  50   AIC:                             1204.\nDf Residuals:                      48   BIC:                             1208.\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst       1.162e+05   7013.324     16.567      0.000    1.02e+05     1.3e+05\nx1         -1.228e+04    1.2e+04     -1.021      0.312   -3.65e+04    1.19e+04\n==============================================================================\nOmnibus:                        0.079   Durbin-Watson:                   0.073\nProb(Omnibus):                  0.961   Jarque-Bera (JB):                0.190\nSkew:                           0.087   Prob(JB):                        0.909\nKurtosis:                       2.753   Cond. No.                         2.41\n==============================================================================\n\nWarnings:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\"\"\"","text/html":"<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.021</td>\n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.001</td>\n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1.043</td>\n</tr>\n<tr>\n  <th>Date:</th>             <td>Mon, 17 Aug 2020</td> <th>  Prob (F-statistic):</th>  <td> 0.312</td> \n</tr>\n<tr>\n  <th>Time:</th>                 <td>06:33:46</td>     <th>  Log-Likelihood:    </th> <td> -600.12</td>\n</tr>\n<tr>\n  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1204.</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td>    48</td>      <th>  BIC:               </th> <td>   1208.</td>\n</tr>\n<tr>\n  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>const</th> <td> 1.162e+05</td> <td> 7013.324</td> <td>   16.567</td> <td> 0.000</td> <td> 1.02e+05</td> <td>  1.3e+05</td>\n</tr>\n<tr>\n  <th>x1</th>    <td>-1.228e+04</td> <td>  1.2e+04</td> <td>   -1.021</td> <td> 0.312</td> <td>-3.65e+04</td> <td> 1.19e+04</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td> 0.079</td> <th>  Durbin-Watson:     </th> <td>   0.073</td>\n</tr>\n<tr>\n  <th>Prob(Omnibus):</th> <td> 0.961</td> <th>  Jarque-Bera (JB):  </th> <td>   0.190</td>\n</tr>\n<tr>\n  <th>Skew:</th>          <td> 0.087</td> <th>  Prob(JB):          </th> <td>   0.909</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>      <td> 2.753</td> <th>  Cond. No.          </th> <td>    2.41</td>\n</tr>\n</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}